{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command creator\n",
    "\n",
    "This notebook is meant to help the user in the composition of the shell command needed for training the neural network, allowing him also to specify where the input data are, where to put the output results and which value to set for each training parameter. By running the first cell in this notebook, the command is composed and printed on screen. The user can choose whether to execute such command within this notebook, by executing the cell in the [Execute command](#execute-command) section, or by copying it to later paste it and run it in a separate terminal.\n",
    "\n",
    "*Note:* Setting a parameter to **None** in the `params` dictionary is equivalent to selecting the default value for such parameter. For additional information about the parameter meaning and their default values, please consult `run.py` in the folder containing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from misc.utils import build_command\n",
    "\n",
    "script_path = os.path.join(os.path.abspath(\"\"),'run.py') # Path to the script to launch\n",
    "\n",
    "ds_folder = \"AerialWaste3.0\"\n",
    "output_root_dir = 'test-experiment' # Root folder for the current experiment\n",
    "img_size = 500\n",
    "\n",
    "params = {\n",
    "\n",
    "    # Enviroment\n",
    "    'gpus': [1],\n",
    "    'experiment_seed': 0,\n",
    "    \n",
    "    # Image folders\n",
    "    'train_image_folder' : os.path.join(ds_folder, 'images'), # Folder with images for the training set\n",
    "    'val_image_folder' : os.path.join(ds_folder, 'images'), # Folder with images for the validation set\n",
    "    'infer_image_folder' : os.path.join(ds_folder, 'images'), # Folder with images for classification\n",
    "    \n",
    "    # Dataset description files\n",
    "    'train_desc_file' : os.path.join(ds_folder, 'training-train-binary.json'), # Json with list of images for training\n",
    "    'val_desc_file' : os.path.join(ds_folder, 'training-val-binary.json'), # Json with list of images for validation\n",
    "    'infer_list_file' : os.path.join(ds_folder, 'testing-binary.json'), # Json with list of images for inference\n",
    "    \n",
    "    # Training parameters\n",
    "    'network': 'resnet', # Model to train (either 'resnet' or 'swint')\n",
    "    'batch_size': 8, # Batch size\n",
    "    'num_epochs': 1, # Number of epochs\n",
    "    'learning_rate': 1e-3, # Learning rate\n",
    "    'pretraining_model': None, # Path to the model for pretraining the whole network. For fine tuning use: os.path.join(output_root_dir, 'checkpoints', 'checkpoint.pth')\n",
    "    \n",
    "    # Network-specific parameters\n",
    "    # ResNet (RN)\n",
    "    'rn_arch': 'resnet50', # ResNet network architecture\n",
    "    'rn_head' : [2048, 1], # Width and depth of the FC layers in the network head\n",
    "    'rn_pretrained' : 'rsp', # Pretraining to use on the backbone (either 'imagenet' or 'rsp')\n",
    "    'rn_first_trainable': 5, # Number-layer mapping in the network source code    \n",
    "    # SwinT (ST)\n",
    "    'st_head' : [768, 1], # Width and depth of the FC layers in the network head\n",
    "    'st_pretrained' : 'rsp', # Pretraining to use on the backbone (either 'imagenet' or 'rsp')\n",
    "    'st_first_trainable': 5, # Number-layer mapping in the network source code\n",
    "    \n",
    "    # Optimizer\n",
    "    'optimizer': 'adam',\n",
    "    # Optimizer-specific parameters\n",
    "    'sgd_momentum': None,\n",
    "    'sgd_weight_decay': None,\n",
    "\n",
    "    # Early stopping\n",
    "    'es_patience': 10,\n",
    "    'es_min_delta': 0.001,\n",
    "    \n",
    "    # Data augmentation\n",
    "    # TRAINING TIME\n",
    "    'train_resize': [img_size, img_size],\n",
    "    'train_fliph_prob': .5,\n",
    "    'train_flipv_prob': .5,\n",
    "    'train_rotate90s': True,\n",
    "    'train_pad': None,\n",
    "\n",
    "    # VALIDATION TIME\n",
    "    'val_resize': [img_size, img_size],\n",
    "    'val_pad': None,\n",
    "\n",
    "    # INFERENCE/CAM TIME\n",
    "    'infer_resize': [img_size, img_size],\n",
    "    'infer_pad': None,\n",
    "\n",
    "    # Output paths\n",
    "    'out_log_file' : os.path.join(output_root_dir, \"output.log\"),\n",
    "    'out_checkpoint_dir' : os.path.join(output_root_dir, \"checkpoints\"),\n",
    "    'out_cam_dir' : os.path.join(output_root_dir, \"cams\"),\n",
    "    'out_pred_dir' : os.path.join(output_root_dir, \"predictions\"),\n",
    "    'out_tb_dir' : os.path.join(output_root_dir, \"tb-logs\"),\n",
    "\n",
    "    # Steps\n",
    "    'make_train': True,\n",
    "    'make_pred': True,\n",
    "    'make_cam': True,\n",
    "}\n",
    "\n",
    "# Print command\n",
    "command = build_command(f'python {script_path}', params)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute command\n",
    "In order to execute the command composed in the previous cell within this notebook, uncomment the next cell.\n",
    "\n",
    "***Note***: the next cell is commented to allow the notebook to be executed in full without launching the training, which usually requires a significant amount of time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !eval {command}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
