{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single image inference\n",
    "\n",
    "This notebook contains the code to perform inference on a single image, thus extracting the classification score for such image and producing its Class Activation Maps (CAMs).\n",
    "In order to do this, the image must be provided as input to a model, whose architecture and weights must be specified respectively in the `model` and `checkpoint_path` variables, assigned in different cells of this notebook. The final cell allows to visualise the outputs produced by such inference process.\n",
    "\n",
    "***Note:*** the classification scores and CAMs obtained from the inference proposed in this notebook are not saved to disk but only displayed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from PIL import Image\n",
    "from nets import ResNet, SwinT\n",
    "from misc.inferutils import get_reshape_transform, get_target_layers\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined parameters\n",
    "checkpoint_path = 'nets/weights/swint-rsp-20-210.pth' # File containing the weights of the model\n",
    "cat_src_file = 'AerialWaste3.0/testing-binary.json' # File containing a list of categories for which to compute CAMs and predictions\n",
    "gpu = 1 # ID of the GPU to use for performing inference\n",
    "img_path = \"AerialWaste3.0/images/23.png\" # Image path\n",
    "resize_size = (1048,1048)\n",
    "# Check parameter file existence\n",
    "assert os.path.isfile(checkpoint_path)\n",
    "assert os.path.isfile(cat_src_file)\n",
    "assert os.path.isfile(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of categories\n",
    "with open(cat_src_file, 'r') as file:\n",
    "    cats = [cat['name'] for cat in json.load(file)['categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image with PIL\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "# Create transform to process image\n",
    "transform = transforms.Compose([transforms.ToImage(), \n",
    "                                transforms.ToDtype(torch.float32, scale=True),\n",
    "                                transforms.Resize(size=resize_size),\n",
    "                                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])  # ImageNet normalization values\n",
    "# Preprocess image\n",
    "input_tensor = transform(image).unsqueeze(0) # Add leading dimesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model [uncomment line related to the model to use for inference]\n",
    "# model = ResNet('resnet50', head=[2048,1], pretraining_model=checkpoint_path, first_trainable=4).to(f\"cuda:{gpu}\")\n",
    "model = SwinT(head=[768,1], pretraining_model=checkpoint_path, first_trainable=4).to(f\"cuda:{gpu}\")\n",
    "# Create GradCam extractor\n",
    "cam = GradCAM(model=model, \n",
    "              target_layers=get_target_layers(model), \n",
    "              reshape_transform=get_reshape_transform(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually compute CAMs\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=None) # Setting the targets to None implies computing CAMs for each output\n",
    "# Extract CAM of the single image\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "# Create visualization\n",
    "rgb_img = np.asarray(image.resize(resize_size), dtype=np.float32)/255\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display outputs \n",
    "print(f\"Classification scores: {cam.outputs[0,:].detach().cpu().numpy()}\")\n",
    "fig,axes = plt.subplots(1,2, figsize=(16,10))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(visualization);\n",
    "for ax in axes:\n",
    "    ax.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
